{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Aazssd5-2eI",
    "outputId": "68944453-5cd0-4be2-dfae-31492455f0bb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting NERDA\n",
      "  Downloading https://files.pythonhosted.org/packages/eb/91/574dbc6aae1958d6be2c63647b4a64caac2196028ca91cc4add870188eca/NERDA-0.8.8-py3-none-any.whl\n",
      "Collecting transformers<=3.5.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3MB 14.7MB/s \n",
      "\u001b[?25hCollecting torch<=1.7.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/5d/095ddddc91c8a769a68c791c019c5793f9c4456a688ddd235d6670924ecb/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8MB)\n",
      "\u001b[K     |████████████████████████████████| 776.8MB 23kB/s \n",
      "\u001b[?25hCollecting progressbar\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/a6/b8e451f6cff1c99b4747a2f7235aa904d2d49e8e1464e0b798272aa84358/progressbar-2.5.tar.gz\n",
      "Collecting pyconll\n",
      "  Downloading https://files.pythonhosted.org/packages/60/7f/148a5b6f99b8a22373bfbcafd9d6776278fec14810ae95c4fe37965f6619/pyconll-3.0.4-py3-none-any.whl\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from NERDA) (3.2.5)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from NERDA) (1.1.5)\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from NERDA) (0.0)\n",
      "Collecting sentencepiece==0.1.91\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/e2/813dff3d72df2f49554204e7e5f73a3dc0f0eb1e3958a4cad3ef3fb278b7/sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 42.3MB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
      "\u001b[K     |████████████████████████████████| 901kB 41.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers<=3.5.1->NERDA) (4.41.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers<=3.5.1->NERDA) (1.19.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<=3.5.1->NERDA) (2.23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<=3.5.1->NERDA) (3.0.12)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<=3.5.1->NERDA) (20.9)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<=3.5.1->NERDA) (2019.12.20)\n",
      "Collecting tokenizers==0.9.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/ac/f5ba028f0f097d855e1541301e946d4672eb0f30b6e25cb2369075f916d2/tokenizers-0.9.3-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9MB 27.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers<=3.5.1->NERDA) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<=1.7.1->NERDA) (3.7.4.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->NERDA) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->NERDA) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->NERDA) (2.8.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->NERDA) (0.22.2.post1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<=3.5.1->NERDA) (8.0.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<=3.5.1->NERDA) (1.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<=3.5.1->NERDA) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<=3.5.1->NERDA) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<=3.5.1->NERDA) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<=3.5.1->NERDA) (3.0.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<=3.5.1->NERDA) (2.4.7)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers<=3.5.1->NERDA) (56.1.0)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->NERDA) (1.4.1)\n",
      "Building wheels for collected packages: progressbar\n",
      "  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for progressbar: filename=progressbar-2.5-cp37-none-any.whl size=12076 sha256=ef475384b8dbef66eef508966c2d9b18ef7b5b74111caa495a11be3c40f1e8ef\n",
      "  Stored in directory: /root/.cache/pip/wheels/c0/e9/6b/ea01090205e285175842339aa3b491adeb4015206cda272ff0\n",
      "Successfully built progressbar\n",
      "\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers, torch, progressbar, pyconll, NERDA\n",
      "  Found existing installation: torch 1.8.1+cu101\n",
      "    Uninstalling torch-1.8.1+cu101:\n",
      "      Successfully uninstalled torch-1.8.1+cu101\n",
      "Successfully installed NERDA-0.8.8 progressbar-2.5 pyconll-3.0.4 sacremoses-0.0.45 sentencepiece-0.1.91 tokenizers-0.9.3 torch-1.7.1 transformers-3.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install NERDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JCPkR7Qxdd2A",
    "outputId": "f425768f-0f4d-499b-ea2e-ada237c31c14",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (3.5.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers) (56.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "SJWNbZmf3DK4",
    "outputId": "79ffd94c-c29e-403d-b306-0118382a923c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     520376\n",
      "False      6457\n",
      "Name: SameLen, dtype: int64\n",
      "526833\n",
      "8871708 9061262\n",
      "True    520376\n",
      "Name: SameLen, dtype: int64\n",
      "520376\n",
      "8742256 8742256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>government</td>\n",
       "      <td>[B-PERSON, I-PERSON, O, B-LOCATION, O, B-MISC, O]</td>\n",
       "      <td>[Corina, Casanova, ,, İsviçre, Federal, Şansölyesidir, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>law</td>\n",
       "      <td>[B-MISC, O, B-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, O, O, O, O, O, O, O, B-MISC, O, O, O]</td>\n",
       "      <td>[Casanova, ,, İsviçre, Federal, Yüksek, Mahkemesi, eski, Başkanı, ,, Nay, Giusep'in, pratiğinde, bir, avukat, olarak, çalıştı, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>government</td>\n",
       "      <td>[B-PERSON, I-PERSON, O, B-MISC, O, O]</td>\n",
       "      <td>[Corina, Casanova, bir, federal, parlementerdir, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>location</td>\n",
       "      <td>[B-PERSON, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-MISC, O, B-MISC, O, B-LOCATION, O, O, O, B-MISC, O]</td>\n",
       "      <td>[Casanova, ,, Hristiyan, Demokrat, Halk, Partisi, üyesi, üyedidir, ve, altı, dilde, konuşmaktadır, :, Romanş, dili, ,, Almanca, ,, Fransızca, ,, İtalyanca, ,, İngilizce, ve, İspanyolca, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>government</td>\n",
       "      <td>[B-ORGANIZATION, I-ORGANIZATION, I-ORGANIZATION, O, B-ORGANIZATION, B-MISC, O, O, O, O]</td>\n",
       "      <td>[İsviçre, Dışişleri, Bakanlığı, ,, İsviçre, federal, yönetiminin, bir, bölümüdür, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category  ...                                                                                                                                                                                          Text\n",
       "0  government  ...                                                                                                                                     [Corina, Casanova, ,, İsviçre, Federal, Şansölyesidir, .]\n",
       "1         law  ...                                                             [Casanova, ,, İsviçre, Federal, Yüksek, Mahkemesi, eski, Başkanı, ,, Nay, Giusep'in, pratiğinde, bir, avukat, olarak, çalıştı, .]\n",
       "2  government  ...                                                                                                                                           [Corina, Casanova, bir, federal, parlementerdir, .]\n",
       "3    location  ...  [Casanova, ,, Hristiyan, Demokrat, Halk, Partisi, üyesi, üyedidir, ve, altı, dilde, konuşmaktadır, :, Romanş, dili, ,, Almanca, ,, Fransızca, ,, İtalyanca, ,, İngilizce, ve, İspanyolca, .]\n",
       "4  government  ...                                                                                                          [İsviçre, Dışişleri, Bakanlığı, ,, İsviçre, federal, yönetiminin, bir, bölümüdür, .]\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.aitimejournal.com/@akshay.chavan/complete-tutorial-on-named-entity-recognition-ner-using-python-and-keras\n",
    "# https://www.kaggle.com/mervetncr/turkish-text-classification-fasttext-and-bert\n",
    "# https://data.mendeley.com/datasets/cdcztymf4k/1\n",
    "# https://www.kaggle.com/behcetsenturk/shrinked-twnertc-turkish-ner-data-by-kuzgunlar\n",
    "# https://web.itu.edu.tr/gulsenc/papers/NERsubmittedColing.pdf \n",
    "#   Şeker, G. A., & Eryiğit, G. (2012). Initial explorations on using CRFs for Turkish\n",
    "#   named entity recognition. Proceedings of COLING 2012, 2459-2474.\n",
    "#4 class :Location, Person, Organization, Misc\n",
    "#import fasttext\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer \n",
    "import os, re, csv, math, codecs\n",
    "\n",
    "# check where you stored the file in order to open it!\n",
    "df= pd.read_csv(r'TWNERTC_TC_Coarse Grained NER_DomainIndependent_NoiseReduction.DUMP', header=None, \n",
    "                names=[\"Category\",\"Tag\",\"Text\"], delimiter='\\t')\n",
    "\n",
    "# comparing number of tags, words if they are not equal then drop.\n",
    "df[\"Tag\"]=df.Tag.str.split()\n",
    "df[\"Text\"]=df.Text.str.split()\n",
    "df[\"LenTag\"]=df['Tag'].apply(len)\n",
    "df[\"LenText\"]=df['Text'].apply(len)\n",
    "# whole dataset\n",
    "df[\"SameLen\"]= np.where(df[\"LenTag\"] == df[\"LenText\"], True, False)\n",
    "print(df[\"SameLen\"].value_counts())\n",
    "print(len(df))\n",
    "print(df[\"LenTag\"].sum(),df[\"LenText\"].sum())\n",
    "df = df[df.SameLen != False]\n",
    "# equal dataset\n",
    "print(df[\"SameLen\"].value_counts())\n",
    "print(len(df))\n",
    "print(df[\"LenTag\"].sum(),df[\"LenText\"].sum())\n",
    "df=df.drop([\"LenTag\",\"LenText\",\"SameLen\"],axis=1)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ZQ4RxyWMOT9",
    "outputId": "b4229684-dcae-4e3c-dce8-d0ee04d7ef2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416300\n",
      "<class 'dict'>\n",
      "52038\n",
      "<class 'dict'>\n",
      "52038\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "split_1 = int(0.8 * len(df))\n",
    "split_2 = int(0.9 * len(df))\n",
    "train_df = df[:split_1]\n",
    "dev_df = df[split_1:split_2]\n",
    "test_df = df[split_2:]\n",
    "\n",
    "training={'sentences': train_df[\"Text\"].tolist(),'tags':train_df[\"Tag\"].tolist()}\n",
    "print(len(training.get('sentences')))\n",
    "print(type(training))\n",
    "\n",
    "validation ={'sentences': dev_df[\"Text\"].tolist(),'tags':dev_df[\"Tag\"].tolist()}\n",
    "print(len(validation.get('sentences')))\n",
    "print(type(validation))\n",
    "\n",
    "testing ={'sentences': test_df[\"Text\"].tolist(),'tags':test_df[\"Tag\"].tolist()}\n",
    "print(len(testing.get('sentences')))\n",
    "print(type(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2wVFgO_O-f96",
    "outputId": "a5016773-dc00-4d52-cb2c-54153bf2ee0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device automatically set to: cuda\n",
      "MODEL CREATED\n"
     ]
    }
   ],
   "source": [
    "dropout = 0.1\n",
    "# hyperparameters for training\n",
    "training_hyperparameters = {\n",
    "'epochs' : 1,\n",
    "'warmup_steps' : 500,                                                   \n",
    "'train_batch_size': 13,                                         \n",
    "'learning_rate': 0.0001\n",
    "}\n",
    "\n",
    "tag_scheme = [\n",
    "'B-PERSON',\n",
    "'I-PERSON',\n",
    "'B-ORGANIZATION',\n",
    "'I-ORGANIZATION',\n",
    "'B-LOCATION',\n",
    "'I-LOCATION',\n",
    "'B-MISC',\n",
    "'I-MISC'\n",
    "]\n",
    "\n",
    "\n",
    "from NERDA.models import NERDA\n",
    "model = NERDA(\n",
    "dataset_training = training,\n",
    "dataset_validation = validation ,\n",
    "tag_scheme = tag_scheme, \n",
    "tag_outside = 'O',\n",
    "transformer = 'dbmdz/bert-base-turkish-cased',\n",
    "dropout = dropout,\n",
    "hyperparameters = training_hyperparameters\n",
    ") \n",
    "print(\"MODEL CREATED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q34o1_7O3DLC"
   },
   "outputs": [],
   "source": [
    "print(type(model))\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "id": "tD9esi23TI2e",
    "outputId": "53caaf8d-6a23-40e5-84bb-20fe3c9ee200"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'NERDA.models.NERDA'>\n",
      "Testing started...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-PERSON</td>\n",
       "      <td>0.647065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I-PERSON</td>\n",
       "      <td>0.685585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B-ORGANIZATION</td>\n",
       "      <td>0.568911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I-ORGANIZATION</td>\n",
       "      <td>0.574827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B-LOCATION</td>\n",
       "      <td>0.751515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I-LOCATION</td>\n",
       "      <td>0.603653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B-MISC</td>\n",
       "      <td>0.683278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I-MISC</td>\n",
       "      <td>0.631968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AVG_MICRO</td>\n",
       "      <td>0.679156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AVG_MACRO</td>\n",
       "      <td>0.643350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Level  F1-Score\n",
       "0        B-PERSON  0.647065\n",
       "1        I-PERSON  0.685585\n",
       "2  B-ORGANIZATION  0.568911\n",
       "3  I-ORGANIZATION  0.574827\n",
       "4      B-LOCATION  0.751515\n",
       "5      I-LOCATION  0.603653\n",
       "6          B-MISC  0.683278\n",
       "7          I-MISC  0.631968\n",
       "0       AVG_MICRO  0.679156\n",
       "0       AVG_MACRO  0.643350"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(model))\n",
    "print(\"Testing started...\")\n",
    "model.evaluate_performance(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A1yQ6Bb6vIht",
    "outputId": "0bfe42ad-f369-4a70-a0da-9fd4cfccbe7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['Türkiye', 'Büyük', 'Millet', 'Meclisi']],\n",
       " [['B-MISC', 'I-MISC', 'I-MISC', 'I-MISC']])"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deneme= 'Türkiye Büyük Millet Meclisi'\n",
    "model.predict_text(deneme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tvo-KSXT2NCD",
    "outputId": "96c421f8-288f-462b-dbda-89d83af2d200"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['Türkiye', 'Büyük', 'Millet', 'Meclisi']],\n",
       " [['B-MISC', 'I-MISC', 'I-MISC', 'I-MISC']])"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'bertNER.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    " \n",
    "# some time later...\n",
    "\n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "loaded_model.predict_text(deneme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "9Xsj50nz3Gyd",
    "outputId": "476ef245-c9df-4b02-ad50-6cae30290044"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_44f7684a-2fca-4bdb-a860-789c3422d7d3\", \"bertNER.sav\", 607683797)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# download ner model to local computer\n",
    "from google.colab import files\n",
    "files.download('bertNER.sav') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYiH5IrzcQ-a"
   },
   "source": [
    "https://towardsdatascience.com/easy-fine-tuning-of-transformers-for-named-entity-recognition-d72f2b5340e3\n",
    "\n",
    "https://medium.com/analytics-vidhya/named-entity-recognition-for-turkish-with-bert-f8ec04a31b0"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
